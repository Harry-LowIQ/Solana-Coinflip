"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
const tslib_1 = require("tslib");
const core_1 = require("@oclif/core");
const anchor = tslib_1.__importStar(require("@project-serum/anchor"));
const bs58_1 = tslib_1.__importDefault(require("bs58"));
const fs_1 = tslib_1.__importDefault(require("fs"));
const path_1 = tslib_1.__importDefault(require("path"));
const BaseCommand_1 = tslib_1.__importDefault(require("../../BaseCommand"));
class MetricsVrf extends BaseCommand_1.default {
    async run() {
        const { args, flags } = await this.parse(MetricsVrf);
        const parsedPath = path_1.default.parse(args.outputFile.startsWith("/") || args.outputFile.startsWith("C:")
            ? args.outputFile
            : path_1.default.join(process.cwd(), args.outputFile));
        this.outputBasePath = path_1.default.join(parsedPath.dir, parsedPath.name);
        if (parsedPath.ext === ".txt" || flags.txt) {
            this.outputTxtFile = `${this.outputBasePath}.txt`;
            if (fs_1.default.existsSync(this.outputTxtFile) && flags.force === false) {
                throw new Error(`output txt file already exists: ${this.outputTxtFile}`);
            }
        }
        if (parsedPath.ext === ".json" || flags.json) {
            this.outputJsonFile = `${this.outputBasePath}.json`;
            if (fs_1.default.existsSync(this.outputJsonFile) && flags.force === false) {
                throw new Error(`output json file already exists: ${this.outputJsonFile}`);
            }
        }
        if (parsedPath.ext === ".csv" || flags.csv) {
            this.outputCsvFile = `${this.outputBasePath}.csv`;
            if (fs_1.default.existsSync(this.outputCsvFile) && flags.force === false) {
                throw new Error(`output csv file already exists: ${this.outputCsvFile}`);
            }
        }
        if (!(this.outputJsonFile || this.outputCsvFile || this.outputTxtFile)) {
            throw new Error(`no output format specified, try --txt, --json, or --csv`);
        }
        const accountCoder = new anchor.BorshAccountsCoder(this.program.idl);
        const aggregatorDiscriminator = Uint8Array.from([
            101, 35, 62, 239, 103, 151, 6, 18,
        ]);
        this.vrfAccounts =
            await this.program.provider.connection.getProgramAccounts(this.program.programId, {
                filters: [
                    {
                        memcmp: {
                            offset: 0,
                            bytes: bs58_1.default.encode(aggregatorDiscriminator),
                        },
                    },
                ],
            });
        const vrfPubkeys = this.vrfAccounts.map((account) => account.pubkey.toString());
        fs_1.default.writeFileSync(this.outputTxtFile, vrfPubkeys.join("\n"));
        // writeAggregators(
        //   aggregators,
        //   this.outputTxtFile,
        //   this.outputJsonFile,
        //   this.outputCsvFile
        // );
    }
    async catch(error) {
        super.catch(error, "failed to filter vrf accounts");
    }
}
exports.default = MetricsVrf;
MetricsVrf.description = "get metrics on switchboard vrfs";
MetricsVrf.hidden = true;
MetricsVrf.flags = {
    ...BaseCommand_1.default.flags,
    force: core_1.Flags.boolean({
        description: "overwrite outputFile if it already exists",
    }),
    queue: core_1.Flags.string({
        description: "oracle queue to filter aggregators by",
        required: false,
    }),
    json: core_1.Flags.boolean({
        description: "output aggregator accounts in json format",
    }),
    csv: core_1.Flags.boolean({
        description: "output aggregator accounts in csv format",
    }),
    txt: core_1.Flags.boolean({
        description: "output aggregator pubkeys in txt format",
    }),
};
MetricsVrf.args = [
    {
        name: "outputFile",
        required: true,
        description: "Output file to save accounts to",
    },
];
// function writeVrfs(
//   vrfs: Aggregator[],
//   outputTxtFile?: string,
//   outputJsonFile?: string,
//   outputCsvFile?: string
// ) {
//   // write txt file
//   if (outputTxtFile) {
//     fs.writeFileSync(
//       outputTxtFile,
//       aggregators.map((a) => a.publicKey.toString()).join("\n")
//     );
//   }
//   // write json file
//   if (outputJsonFile) {
//     fs.writeFileSync(outputJsonFile, JSON.stringify(aggregators, undefined, 2));
//   }
//   // write csv file or output to console
//   if (outputCsvFile) {
//     const headers = [
//       "name",
//       "metadata",
//       "publicKey",
//       "authority",
//       "queuePubkey",
//       "crankPubkey",
//       "historyBuffer",
//       "oracleRequestBatchSize",
//       "minOracleResults",
//       "minJobResults",
//       "minUpdateDelaySeconds",
//       "varianceThreshold",
//       "forceReportPeriod",
//     ];
//     const rows = aggregators.map((a) => {
//       return [
//         a.name,
//         a.metadata,
//         a.publicKey.toString(),
//         a.authority.toString(),
//         a.queuePubkey.toString(),
//         a.crankPubkey.toString(),
//         a.historyBuffer.toString(),
//         a.oracleRequestBatchSize.toString(),
//         a.minOracleResults.toString(),
//         a.minJobResults.toString(),
//         a.minUpdateDelaySeconds.toString(),
//         a.varianceThreshold.toString(),
//         a.forceReportPeriod.toString(),
//       ];
//     });
//     if (outputCsvFile) {
//       fs.writeFileSync(
//         outputCsvFile,
//         `${headers.join(",")}\n${rows.map((r) => r.join(",")).join("\n")}`
//       );
//     }
//     // if (!flags.silent) {
//     //   console.table(table.rows, table.headers);
//     // }
//   }
// }
